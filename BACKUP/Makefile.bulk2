# On 18 Sep 2021, rewriting for the following goals:
#
#   - avoid large pipes which reside in memory
#   - create list of excluded files
#   - separate out fgrep and egrep exclusions
#   - perhaps better commenting/formatting
#   - if sort creates large files maybe changed /tmp dir to be safe?...
#   - or use memory limited sort?
#
# Files that must exist: fgrep-commented.txt egrep-commented.txt

# Below, NUL means \0 the null character ASCII 0


# the final target

all: filelist.txt excluded-by-egrep.txt excluded-by-fgrep.txt

# and clean

clean:
	rm afad-minus-egrep.txt previouslydone.txt.srt.dupes afad-not-yet-backed-up.txt egrep-pure.txt excluded-by-egrep.txt excluded-by-fgrep.txt big-by-dir.txt big-by-file.txt statlist.txt filelist.txt doesnotexist.txt afad-minus-egrep-fgrep.txt afad.txt previouslydone.txt.srt previouslydone.txt fgrep-pure.txt part[1234567] egrep-semi-pure.txt *~

# some variables in case we want to change things up

nice = nice -n 19
sortoptions = -S 8G

# insisting that an fgrep string start with a / prevents accidentally
# matching purely numeric strings

fgrep-pure.txt: Makefile fgrep-commented.txt
	egrep '^/' fgrep-commented.txt | perl -nle 'print "\0$$_\0"' > fgrep-pure.txt

# the "commented" egrep file may have comments or blank lines in them; this
# removes them and creates the "pure" version

# egrep-semi-pure.txt lets me test regex against big by dir

egrep-pure.txt: Makefile egrep-commented.txt
	egrep -v '^\#|^ *$$' egrep-commented.txt | perl -nle 'print "^\0$$_\0"' > egrep-pure.txt; egrep -v '^\#|^ *$$' egrep-commented.txt | perl -nle 'print " $$_\$$"' > egrep-semi-pure.txt; 

# find all the files I've previously backed up:
#
#  - the format of *.exclude is: filename NUL timestamp (thus -t '\0')
#
#  - Some files are backed up multiple times (if they change) and I
#  want to find the most recent backups first (thus -k2nr)
#
#  - This command doesn't delete duplicates but another one does
#
#  - don't use more than 8G of memory sort (-S 8G)
#
# 

previouslydone.txt.dupes.srt: Makefile /root/massback-bulk/*.exclude
	$(nice) sort $(sortoptions) -mu /root/massback-bulk/*.exclude | bc-prevdone2moredone.pl | sort $(sortoptions) -u > previouslydone.txt.dupes.srt

# thinking that piping maybe *wasn't* my problem, get a list of files
# with mtime and size, after egreping and fgreping out ones I don't
# want

# in theory, fgrep or egrep could match a non-file field (for egrep, can solve this with an achor, unlikely to be an issue for fgrep)

# the tee's to various files is for debugging

# TODO: need to change format of files-to-backup.txt to match prevdone
files-to-backup.txt: Makefile $(converted) egrep-pure.txt fgrep-pure.txt
		$(nice) perl -anle 's%.*?/%/%; $$F[0]=~s/\..*//; if ($$F[4] eq "f") {print "\0$$_\0$$F[0]\0$$F[1]"}' $(converted) | egrep -avf egrep-pure.txt | fgrep -avf fgrep-pure.txt | perl -F'\0' -anle 'print "$$F[1]\t$$F[2]\0$$F[3]"' | $(nice) sort $(sortoptions) > files-to-backup.txt

# sort $(sortoptions) > afad.txt


# find the most recent backup for each file in previouslydone.txt
#
#  - I couldn't find options to uniq to make this work without having
#  to go through a second sort, so I do the below

# previouslydone.txt.srt: previouslydone.txt
#	$(nice) sort $(sortoptions) -t '\0' -k1,1 -u previouslydone.txt > previouslydone.txt.srt

# from previouslydone.txt.srt create alternate names for files that
# have also been backed up in theory

# TODO: shouldnt need cat here

previouslydone.txt.srt.dupes: previouslydone.txt.srt Makefile /home/user/BCGIT/BACKUP/bc-conversions.txt /home/user/bc-conversions-private.txt
	$(nice) bc-prevdone2moredone.pl previouslydone.txt.srt | sort $(sortoptions) -u > previouslydone.txt.srt.dupes

# afad.txt is all files and directories (full path) with format:
#
# filename NUL mtime NUL size

# as of 6 Oct 2021, alternate filenames are handled by
# prevdone2moredone, so we can get afad.txt directly from "raw"
# filelists

# TODO: maybe use alternate temp directory for sort

# file lists on all drives I recognize

converted=$(shell egrep -v '^\#|^$$' /home/barrycarter/BCGIT/BRIGHTON/mounts.txt | perl -anle 'print "$$F[0]/$$F[1]-files.txt"')

# the $$F[0]=~s/\..*// removes fractions from timestamps
# $F[4] is file type (directories excluded)

# unhappy about piped sort below-- if this does bad things, consider
# breaking into afad.txt and afad.txt.srt

afad-minus-egrep-fgrep.txt: $(converted) Makefile
	$(nice) perl -anle 's%.*?/%/%; $$F[0]=~s/\..*//; if ($$F[4] eq "f") {print "\0$$_\0$$F[0]\0$$F[1]"}' $(converted) | egrep -avf egrep-pure.txt | fgrep -avf fgrep-pure.txt | perl -pnle 's/^\0//' | sort $(sortoptions) > afad-minus-egrep-fgrep.txt

# | perl -pnle 's/\0[^\0]*$$//' > afad-name-date-only.txt

afad.txt.srt: afad.txt
	$(nice) sort $(sortoptions) afad.txt > afad.txt.srt

afad-name-date-only.txt.srt:
	$(nice) sort $(sortoptions) afad-name-date-only.txt > afad-name-date-only.txt.srt

# sort $(sortoptions) > afad.txt

# all files and directories minus those already backed up

# because I only look at the latest backup, if afad date is less than that, we should assume afad file HAS been backed up

# TODO: another option here would be to list ALL backups of a given
# file and require afad match any one of them (which would eliminate a
# sort and could make things faster)

afad-not-yet-backed-up.txt: Makefile afad.txt previouslydone.txt.srt.dupes
	$(nice) join --check-order -a 1 -t '\0' afad.txt previouslydone.txt.srt.dupes | perl -nle 's/\t/\0/; print "\0$$_"' > afad-not-yet-backed-up.txt

# all files through the egrep filter

afad-minus-egrep.txt: egrep-pure.txt afad-not-yet-backed-up.txt Makefile
	$(nice) egrep -avf egrep-pure.txt afad-not-yet-backed-up.txt > afad-minus-egrep.txt

# files excluded by egrep

excluded-by-egrep.txt: Makefile egrep-pure.txt afad-not-yet-backed-up.txt
	$(nice) egrep -af egrep-pure.txt afad-not-yet-backed-up.txt > excluded-by-egrep.txt

# and then by fgrep

# afad-minus-egrep-fgrep.txt: Makefile fgrep-pure.txt afad-minus-egrep.txt
#	$(nice) fgrep -avf fgrep-pure.txt afad-minus-egrep.txt > afad-minus-egrep-fgrep.txt

# files excluded by fgrep

excluded-by-fgrep.txt: Makefile fgrep-pure.txt afad-minus-egrep.txt
	-fgrep -af fgrep-pure.txt afad-minus-egrep.txt > excluded-by-fgrep.txt

# and then exclude previously excluded files

# afad-minus-egrep-fgrep-previous-backup.txt: Makefile afad-minus-egrep-fgrep.txt previouslydone.txt.srt
#	$(nice) join --check-order -a 1 -t '\0' afad-minus-egrep-fgrep.txt previouslydone.txt.srt | perl -F'\0' -anle 'unless ($$F[1] eq $$F[4]) {print $$_}' > afad-minus-egrep-fgrep-previous-backup.txt

filelist.txt: afad-minus-egrep-fgrep.txt
	bc-chunk-backup3.pl --checkfile --limit=10,000,000,000 --debug afad-minus-egrep-fgrep.txt

# this creates filelist.txt faster, shows all files, but doesnt check if file exists

filelistfast.txt: afad-minus-egrep-fgrep.txt
	bc-chunk-backup3.pl --limit=10,000,000,000,000,000,00 --debug afad-minus-egrep-fgrep.txt

######## dangerous /dev/shm experimentation

/dev/shm/back1: $(converted) Makefile
	$(nice) perl -anle 's%.*?/%/%; $$F[0]=~s/\..*//; if ($$F[4] eq "f") {print "\0$$_\0$$F[0]\0$$F[1]"}' $(converted) > /dev/shm/back1

###### and piecewise again

# this is a list of allfiles on my drives excluding those in egrep and
# fgrep files that don't need to be backedup

allfiles-minus-egrep-fgrep.txt: $(converted) Makefile egrep-pure.txt fgrep-pure.txt
	$(nice) bc-filelist4backup.pl $(converted) | egrep -avf egrep-pure.txt | fgrep -avf fgrep-pure.txt | perl -pnle 's/^\0//' > allfiles-minus-egrep-fgrep.txt

# the -u here shouldn't be necessary because each file should appear
# only once (but things get f'd up sometimes)

allfiles-minus-egrep-fgrep.txt.srt: allfiles-minus-egrep-fgrep.txt
	$(nice) sort $(sortoptions) -u allfiles-minus-egrep-fgrep.txt -o allfiles-minus-egrep-fgrep.txt.srt

# all files previously backed up, with original backup names and then dupes

previouslydone.dupes.txt: Makefile /root/massback-bulk/*.exclude /home/user/BCGIT/BACKUP/bc-conversions.txt /home/user/bc-conversions-private.txt
	$(nice) bc-prevdone2moredone.pl /root/massback-bulk/*.exclude > previouslydone.dupes.txt

previouslydone.dupes.txt.srt: previouslydone.dupes.txt
	$(nice) sort $(sortoptions) -u previouslydone.dupes.txt -o previouslydone.dupes.txt.srt

# the reversed files don't really contribute to backup but make it
# easier to seach for files by ending part/path instead of full name
# (including time for reference); rev does not handle nulls well

previouslydone.dupes.rev: previouslydone.dupes.txt
	perl -F'\0' -anle 'print "$F[1]\t$F[0]"' previouslydone.dupes.txt | rev > previouslydone.dupes.rev

previouslydone.dupes.rev.srt: previouslydone.dupes.rev
	$(nice) sort $(sortoptions) previouslydone.dupes.rev -o previouslydone.dupes.rev.srt

filestobackup.txt: previouslydone.dupes.txt.srt allfiles-minus-egrep-fgrep.txt.srt
	perl -F'\0' -anle 'print "$F[0]\0$F[1]"' allfiles-minus-egrep-fgrep.txt.srt | comm -23 - previouslydone.dupes.txt.srt > filestobackup.txt

filestobackup-plus.txt: filestobackup.txt allfiles-minus-egrep-fgrep.txt.srt
	perl -pnle 's/\0.*//' filestobackup.txt | join -t '\0' - allfiles-minus-egrep-fgrep.txt.srt > filestobackup-plus.txt

	

# perl -F'\0' -anle 'print "\0$F[1]\0$F[2]"' allfiles-minus-egrep-fgrep.txt.srt | comm -23 - previouslydone.dupes.txt.srt > temp0.txt &



part4: part3
	$(nice) bc-prevdone2moredone.pl part3 > part4

part5: part4
	$(nice) sort $(sortoptions) -u part4 -o part5

part6: part2 part5
	perl -pnle 's/\0[^\0]*$$//' part2 | comm -23 - part5 > part6

statlist.txt: part6 part2
	join -t '\0' -o '2.1 2.2 2.3' part6 part2 | bc-chunk-backup3.pl --limit=10,000,000,000,000,000,000 --debug

big-by-dir.txt: statlist.txt
	bc-total-bytes.pl statlist.txt | sort -nr > big-by-dir.txt

big-by-file.txt: statlist.txt
	sort -k1nr statlist.txt > big-by-file.txt
