# On 18 Sep 2021, rewriting for the following goals:
#

# TODO: make sure all sort use $sortoptions and maybe also $nice

#   - avoid large pipes which reside in memory (it turns out this is
#   ok if the pipes "move" fast enough this isn't an issue-- it IS an
#   issue for sort (which has to wait for all its input before
#   sorting) but using "-S 1G" helps
#
#   TODO: create list of excluded files
#
#   DONE: separate out fgrep and egrep exclusions
#
#   TODO: perhaps better commenting/formatting [low pri]
#
#   TODO: (maybe) if sort creates large files maybe changed /tmp dir
#   to be safe? (except I think /tmp is actually faster than USB tmp
#   dirs)
#
#   DONE: or use memory limited sort?

# Files that must exist:
#
#  - fgrep-commented.txt
#  - egrep-commented.txt
#  - links.d (must contain at least one file, but can be an empty file)

# the very top line (first target) is what's made by default, so set
# it to what we need below

# Below, NUL means \0 the null character ASCII 0

default: tobackup.oneshot excluded-by-egrep.txt excluded-by-fgrep.txt excluded-by-weekly.txt

#<!--------- START COMMENT ---------!>

# converted: a list of all file lists on all mounted drives

# nice: the nice level we run at

# sortoptions: sort options to limit memory use

# chunkopts: sent via command line, eg 'chunkopts="--debug
# --checkfile"' to run bc-chunk-backup3.pl with options when
# finalizing backup

#<!--------- END COMMENT ---------!>

converted = $(shell egrep -v '^\#|^$$' /home/barrycarter/BCGIT/BRIGHTON/mounts.txt | perl -anle 'print "$$F[0]/$$F[1]-files.txt"')

nice = nice -n 19

sortoptions = -S 1G

#<!--------- START COMMENT ---------!>

# A list of all files previously backed up in one ugly pipe (note that
# "oneshot" here means I do it all at once, not that I'm only doing it
# one time). Steps (in pipe order):

#  - egrep: remove symlinks (which for some reason start with h, which
#  could mean hard link, except that hard links are indistinguisable
#  from regular files, but whatever) from backed up files because they
#  do weird things

# TODO: figure out what 'h' really means

#  - perl: replace things like \001 in file backup lists with the
#  octal character equivalent, since that's how current filelist is
#  printed; then print the date and filename, adding a "+" between
#  yyyy-mm-dd and hh:mm:ss to match find's "+" format

#  - sort: sort by filename and then by date-- this groups all backups
#  of a given file together, in reverse date order

#  - uniq: get the latest backup for each file (in theory, we don't
#  need the last backup and could use all backups, but this reduced
#  the load on the join)

#  - join: convert the list of backed-up files to where the files
#  currently are using the files in links.d that list "old-location
#  TAB new-location"; if the links.d files don't have an entry for
#  a given file, assume the file is still in the same place it was
#  backed up

# TODO: the join above could use "perl -f" or similar to see if the
# file's target location still exists (regardless of whether it's
# moved or in its original location), but this could be timeconsuming

#  - perl: use the output of join to print file's new location
#  depending on whether join found a match for the filename

#  - sort: sort the file by mtime since we plan to join it to another file

#<!--------- END COMMENT ---------!>

previouslydone.oneshot: /mnt/villa/massback-bulk/*.toc links.txt
	$(nice) egrep -hv '^h' /mnt/villa/massback-bulk/*.toc | perl -nle '@F=split(/\s+/, $$_, 6); $$F[5]=~s/\\(\d{3})/chr(oct($$1))/eg; print "$$F[3]+$$F[4]\t/$$F[5]"' | sort -t '	' $(sortoptions) -k2b,2 -k1r | uniq -f1 | join -e '*' -a 1 -t '	' -1 2 -2 1 -o '1.1 2.2 0' - links.txt | perl -F'\t' -anle 'if ($$F[1] eq "*") {print "$$F[0] $$F[2]"} else {print "$$F[0] $$F[1]"}' | sort $(sortoptions) -k1b,1 -o previouslydone.oneshot


#<!--------- START COMMENT ---------!>

# A list of all files on my hard drives (note that "oneshot" here
# means I do it all at once, not that I'm only doing it one
# time). Steps (in pipe order):

# NOTE: I could theoretically fgrep/egrep out files I don't want to
# backup at a fairly early stage, but I change the fgrep and egrep
# files frequently, so I want to have that as a separate step

#  - perl: remove fractional part of timestamp, determine that this is
#  a true file (not a directory, symlink, or something else), then
#  print in "mtime SPACE filename TAB size" format. I must keep mtime
#  and filename in same field (meaning no tab between them) because I
#  need to join on them against previouslydone.oneshot and join
#  doesn't allow multi-field joining. I will need size eventually, but
#  putting it in a seperate field (using TAB) lets me "carry it along"
#  without harming anything.

#  - sort: sort the results by mtime and filename (and technically
#  size) because join requires sorted files

#  - join: determine which files are on disk, but have never been
#  backed up with their current mtime (if they're backed up with a
#  different mtime, past or future, they still need to be backed up
#  again), thus generating the list of unbacked up files.


#<!--------- END COMMENT ---------!>

ondisk.oneshot: $(converted) previouslydone.oneshot
	$(nice) perl -F"\t" -anle '$$F[0]=~s/\..*//; if ($$F[4] eq "f") {print "$$F[0] $$F[8]\t$$F[1]"}' $(converted) | sort -t '	' $(sortoptions) -k 1b,1 | join -v 1 -t '	' - previouslydone.oneshot > ondisk.oneshot

#<!--------- START COMMENT ---------!>

# The list of files that have never been backed up, minus the files I
# don't want to backup. Steps (in pipe order):

#  - perl: replace the tabs in ondisk.oneshot with nuls, so the
#  filename will be bracketed by nulls. As below, the fgrep-pure.txt
#  and egrep-pure.txt files are also bracketed by nulls, so filenames
#  have to match the patterns "exactly" with no leftover; this is a
#  hack way of doing grep's -x option when there are additional fields

#  - egrep: remove files matching the egrep-pure.txt file

#  - fgrep: remove files matching the fgrep-pure.txt file

#  - tac: from the previous commands, ondisk.oneshot is in mtime
#  order; I prefer to backup most recent files first, so tac reverses
#  this order

#  - bc-chunk-backup3.pl: counts up files until 10GB and creates
#  files.txt (for tarring) and big-by-dir.txt and big-by-file.txt (to
#  help figure out which files slipped through the fgrep and egrep)

#<!--------- END COMMENT ---------!>

tobackup.oneshot: ondisk.oneshot fgrep-pure.txt egrep-pure.txt
	$(nice) perl -nle '/(\S+)\s+(.*?)\t(.*)$$/; print "\0$$2\0$$1\0$$3\0"' ondisk.oneshot | egrep -avf egrep-pure.txt | fgrep -avf fgrep-pure.txt | fgrep -avf weekly-pure.txt | tac | bc-chunk-backup3.pl $(chunkopts)

#<!--------- START COMMENT ---------!>

# Convert the commented versions of the fgrep and egrep files to the
# pure versions (by removing blank lines and comments and bracketing
# patterns with nulls)

# fgrep lines must be complete paths (since we are doing full line
# matching) and thus must start with '/'; any line that doesn't is
# probably an error (this doesn't apply to the egrep file because
# lines, at least in theory, could start with ".*" or similar, though
# they probably shouldn't)

# weekly-pure.txt is a list of files backed up weekly that I don't
# need to backup on these incremental backups. The steps to create it

#  - perl: look for all lines that have a "/" in them and delete
#  everything up to that "/"; in other words, print just filename,
#  bracketed by nulls

#  - ls: find all files matching latest*.list, the toc for my weekly
#  backups, sorted by most recent first

#  - head: find the most recent weekly backup file

#  - sort: unnecessary sort to put these in order

#<!--------- END COMMENT ---------!>

weekly-pure.txt: /mnt/villa/massback-bulk/latest-????????.list
	perl -nle 'if (s%^.*?/%/%) {print "\0$$_\0"}' `ls -t /mnt/villa/massback-bulk/latest-????????.list | head -1` | sort > weekly-pure.txt

fgrep-pure.txt: fgrep-commented.txt
	egrep '^/' fgrep-commented.txt | perl -nle 'print "\0$$_\0"' > fgrep-pure.txt

egrep-pure.txt: egrep-commented.txt
	egrep -v '^\#|^ *$$' egrep-commented.txt | perl -nle 'print "^\0$$_\0"' > egrep-pure.txt

#<!--------- START COMMENT ---------!>

# the links.d/*-links.txt files all give "old-location TAB
# new-location"; this command combines them into a single sorted file
# for join purposes

# the "-k 1b,1" is required by join-- if not used, funny characters
# will break join even though "sort -c" (without "-k 1b,1") reports no
# errors (had to remove the -u because the ,1 limits -u to first field)

#<!--------- END COMMENT ---------!>

links.txt: links.d/*-links.txt
	$(nice) sort $(sortoptions) -t '	' -k 1b,1 links.d/*-links.txt > links.txt

#<!--------- START COMMENT ---------!>

# TODO: perhaps add 'tee' to create intermediate files for debugging
# (using some clever Make options to be able to turn it off and on?)

# TODO: maybe use alternate temp directory for sort

# TODO: perhaps create excluded-by-grep.txt that lists which files
# were excluded by my greps

# TODO: (maybe) confirm Makefile doesn't have any $F[1] type stuff (because $s are special to make and must be escaped with another $); we could also check that the base files for the Makefile exist

# this command will confirm there are no $ that are not followed by $ or paren:
# egrep -v '^$|^#' Makefile | egrep '[^\$]\$[^\$\(]
# and below is how it must be written in Makefile (currently not used)

# TODO: maybe rewrite "clean" but maybe not

#check: Makefile
#	egrep -v '^$$|^#' Makefile | egrep '[^\$$]\$$[^\$$\(]'

#clean:
#	rm allfiles-minus-egrep-fgrep.txt* previouslydone.dupes.* filestobackup-plus.txt* filelist.txt statlist.txt big-by-dir.txt big-by-file.txt *-pure.txt *~ doesnotexist.txt

#<!--------- END COMMENT ---------!>

#<!--------- START COMMENT ---------!>

# Files that aren't strictly necessary, but can be useful to see what
# files are excluded and how

#<!--------- END COMMENT ---------!>

excluded-by-egrep.txt: egrep-pure.txt ondisk.oneshot
	$(nice) perl -nle '/(\S+)\s+(.*?)\t(.*)$$/; print "\0$$2\0$$1\0$$3\0"' ondisk.oneshot | egrep -af egrep-pure.txt > excluded-by-egrep.txt

excluded-by-fgrep.txt: fgrep-pure.txt ondisk.oneshot
	$(nice) perl -nle '/(\S+)\s+(.*?)\t(.*)$$/; print "\0$$2\0$$1\0$$3\0"' ondisk.oneshot | fgrep -af fgrep-pure.txt > excluded-by-fgrep.txt

excluded-by-weekly.txt: weekly-pure.txt ondisk.oneshot
	$(nice) perl -nle '/(\S+)\s+(.*?)\t(.*)$$/; print "\0$$2\0$$1\0$$3\0"' ondisk.oneshot | fgrep -af weekly-pure.txt > excluded-by-weekly.txt
