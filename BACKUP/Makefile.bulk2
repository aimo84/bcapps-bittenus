# On 18 Sep 2021, rewriting for the following goals:
#
#   - avoid large pipes which reside in memory
#   - create list of excluded files
#   - separate out fgrep and egrep exclusions
#   - perhaps better commenting/formatting
#   - if sort creates large files maybe changed /tmp dir to be safe?...
#   - or use memory limited sort?
#
# Files that must exist: fgrep-commented.txt egrep-commented.txt

# the very top line (first target) is what's made by default, so set
# it to "all" below

default: all

# Below, NUL means \0 the null character ASCII 0

#<!--------- START COMMENT ---------!>

# converted: a list of all file lists on all mounted drives

# nice: the nice level we run at

# sortoptions: sort options to limit memory use

#<!--------- END COMMENT ---------!>

converted = $(shell egrep -v '^\#|^$$' /home/barrycarter/BCGIT/BRIGHTON/mounts.txt | perl -anle 'print "$$F[0]/$$F[1]-files.txt"')

nice = nice -n 19

sortoptions = -S 8G

#<!--------- START COMMENT ---------!>

# a list of all files on the drive, then sorted

#<!--------- END COMMENT ---------!>

allfiles.txt: $(converted)
	$(nice) bc-filelist4backup.pl --debug $(converted) > allfiles.txt

allfiles.txt.srt: allfiles.txt
	$(nice) sort $(sortoptions) -u allfiles.txt -o allfiles.txt.srt

#<!--------- START COMMENT ---------!>

# a list of all files currently on the drive, excluding those I don't
# want to backup, then sorted so that I can use it with comm

#<!--------- END COMMENT ---------!>

allfiles-minus-egrep-fgrep.txt: $(converted) egrep-pure.txt fgrep-pure.txt
	$(nice) bc-filelist4backup.pl $(converted) | egrep -avf egrep-pure.txt | fgrep -avf fgrep-pure.txt | perl -pnle 's/^\0//' > allfiles-minus-egrep-fgrep.txt

# the -u here shouldn't be necessary because each file should appear
# only once (but things get f'd up sometimes)

allfiles-minus-egrep-fgrep.txt.srt: allfiles-minus-egrep-fgrep.txt
	$(nice) sort $(sortoptions) -u allfiles-minus-egrep-fgrep.txt -o allfiles-minus-egrep-fgrep.txt.srt

#<!--------- START COMMENT ---------!>

# a list of all files I've backed up, then sorted by filename and
# date, and then find latest backup for each, then add dupes

# Note that -k6 sorts from field 6 to the end of the line so spaces in
# filenames are handled ok

#<!--------- END COMMENT ---------!>

previouslydone.txt.srt: /root/massback-bulk/*.toc
	$(nice) sort $(sortoptions) -k6 -k4r,5r -u /root/massback-bulk/*.toc -o previouslydone.txt.srt

previouslydone.txt.srt.unq: previouslydone.txt.srt
	$(nice) sort $(sortoptions) -k6 -u previouslydone.txt.srt -o previouslydone.txt.srt.unq

previouslydone.dupes.txt: previouslydone.txt.srt.unq /home/user/BCGIT/BACKUP/bc-conversions.txt /home/user/bc-conversions-private.txt
	$(nice) bc-tar2exclude.pl previouslydone.txt.srt.unq | bc-prevdone2moredone.pl > previouslydone.dupes.txt

previouslydone.dupes.txt.srt: previouslydone.dupes.txt
	$(nice) sort $(sortoptions) -u previouslydone.dupes.txt -o previouslydone.dupes.txt.srt

#<!--------- START COMMENT ---------!>

# the list of files to backup, meaning those that are:

#   - on the disk currently
#   - not excluded from backup
#   - have not been backed up under either their current or old names

# then rejoined so the final result includes "name \0 mtime \0 size"
# and then sorted by date so newest files get backed up first (that
# sounds odd, but makes sense because more recent files are generally
# more important)

#<!--------- END COMMENT ---------!>

filestobackup-plus.txt: previouslydone.dupes.txt.srt allfiles.txt.srt
	perl -F'\0' -anle 'print "$$F[0]\0$$F[1]"' allfiles.txt.srt | comm -23 - previouslydone.dupes.txt.srt | perl -pnle 's/\0.*//' | join -t '\0' - allfiles-minus-egrep-fgrep.txt.srt > filestobackup-plus.txt

filestobackup-plus.txt.srt: filestobackup-plus.txt
	$(nice) sort $(sortoptions) -t '\0' -k2nr filestobackup-plus.txt -o filestobackup-plus.txt.srt


#<!--------- START COMMENT ---------!>

# create filelist.txt (created by same program which creates
# statlist.txt and thus not listed below) in a form that can be sent
# directly to tar, and use statlist.txt to determine which files and
# directories use the most space, useful for trimming

#<!--------- END COMMENT ---------!>

# TODO: have a flip switch for limit (10GB is normal, infinity for testing)

statlist.txt: filestobackup-plus.txt.srt
	bc-chunk-backup3.pl --limit=999999999999999999 filestobackup-plus.txt.srt

big-by-dir.txt: statlist.txt
	bc-total-bytes.pl statlist.txt | sort -nr > big-by-dir.txt

big-by-file.txt: statlist.txt
	sort -k1nr statlist.txt > big-by-file.txt

#<!--------- START COMMENT ---------!>

# Convert the commented versions of the fgrep and egrep files to the
# pure versions (by removing blank lines and comments)

# fgrep lines must be complete paths (since we are doing full line
# matching) and thus must start with '/'; any line that doesn't is
# probably an error

#<!--------- END COMMENT ---------!>

fgrep-pure.txt: fgrep-commented.txt
	egrep '^/' fgrep-commented.txt | perl -nle 'print "\0$$_\0"' > fgrep-pure.txt

egrep-pure.txt: egrep-commented.txt
	egrep -v '^\#|^ *$$' egrep-commented.txt | perl -nle 'print "^\0$$_\0"' > egrep-pure.txt

#<!--------- START COMMENT ---------!>

# the final target is filelist.txt (but using statlist.txt since
# filelist.txt is implicit) but including big-by-file.txt and
# big-by-dir.txt because I want them too

# clean removes all files created by this Makefile and emacs droppings

#<!--------- END COMMENT ---------!>

all: statlist.txt big-by-file.txt big-by-dir.txt

clean:
	rm allfiles-minus-egrep-fgrep.txt* previouslydone.dupes.* filestobackup-plus.txt* filelist.txt statlist.txt big-by-dir.txt big-by-file.txt *-pure.txt *~ doesnotexist.txt

#<!--------- START COMMENT ---------!>

# TODO: perhaps add 'tee' to create intermediate files for debugging

# TODO: filtering previous backups to just find the most recent
# version of each backup would make previouslydone.dupes.txt a bit
# smaller

# TODO: maybe use alternate temp directory for sort

# TODO: could filelist.txt be made directly from statlist.txt?

#<!--------- END COMMENT ---------!>

#<!--------- START COMMENT ---------!>

# Helpful but unnecessary targets:

#   - excluded-by-egrep.txt: files excluded by egrep

#   - excluded-by-fgrep.txt not needed, full lines in file already

#   - previouslydone.dupes.rev.srt: list of backed up files, reversed, to
#   make it easier to find files by knowing just the lat part of their
#   filename

#   - check: confirm Makefile doesn't have any $F[1] type stuff (because $s are special to make and must be escaped with another $)

#<!--------- END COMMENT ---------!>


excluded-by-egrep.txt: egrep-pure.txt $(converted)
	$(nice) bc-filelist4backup.pl $(converted) | egrep -af egrep-pure.txt > excluded-by-egrep.txt

# using perl to reverse lines, rev freaks on multi-byte caracters

previouslydone.dupes.rev: previouslydone.dupes.txt
	perl -F'\0' -anle 'print "$$F[1]\t$$F[0]"' previouslydone.dupes.txt | perl -nle 'chomp; print join("", reverse(split(//, $_)))' > previouslydone.dupes.rev

previouslydone.dupes.rev.srt: previouslydone.dupes.rev
	$(nice) sort $(sortoptions) previouslydone.dupes.rev -o previouslydone.dupes.rev.srt

# this command will confirm there are no $ that are not followed by $ or paren:
# egrep -v '^$|^#' Makefile | egrep '[^\$]\$[^\$\(]
# and below is how it must be written in Makefile

check: Makefile
	egrep -v '^$$|^#' Makefile | egrep '[^\$$]\$$[^\$$\(]'
